{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ca9cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manny\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      author                                               text\n",
      "0   HAMILTON  FEDERALIST. No. 1 General Introduction For the...\n",
      "1        JAY  FEDERALIST No. 2 Concerning Dangers from Forei...\n",
      "2        JAY  FEDERALIST No. 3 The Same Subject Continued (C...\n",
      "3        JAY  FEDERALIST No. 4 The Same Subject Continued (C...\n",
      "4        JAY  FEDERALIST No. 5 The Same Subject Continued (C...\n",
      "5   HAMILTON  FEDERALIST No. 6 Concerning Dangers from Disse...\n",
      "6   HAMILTON  FEDERALIST. No. 7 The Same Subject Continued (...\n",
      "7   HAMILTON  FEDERALIST No. 8 The Consequences of Hostiliti...\n",
      "8   HAMILTON  FEDERALIST No. 9 The Union as a Safeguard Agai...\n",
      "9    MADISON  FEDERALIST No. 10 The Same Subject Continued (...\n",
      "10  HAMILTON  FEDERALIST No. 11 The Utility of the Union in ...\n",
      "11  HAMILTON  FEDERALIST No. 12 The Utility of the Union In ...\n",
      "12  HAMILTON  FEDERALIST No. 13 Advantage of the Union in Re...\n",
      "13   MADISON  FEDERALIST No. 14 Objections to the Proposed C...\n",
      "14  HAMILTON  FEDERALIST No. 15 The Insufficiency of the Pre...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "df = pd.read_csv('federalist.csv',dtype={'author':'category'},)\n",
    "y = df.author\n",
    "X = df.text\n",
    "\n",
    "\n",
    "print(df[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c0f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAMILTON OCCURENCE: 49\n",
      "HAMILTON AND MADISON OCCURENCE: 3\n",
      "HAMILTON OR MADISON OCCURENCE: 11\n",
      "JAY OCCURENCE: 5\n",
      "MADISON OCCURENCE: 15\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for auth in df[\"author\"].cat.categories:\n",
    "    counts[auth] =0\n",
    "\n",
    "for auth in y:\n",
    "    if auth in counts:\n",
    "        counts[auth] += 1\n",
    "\n",
    "for auth in counts:\n",
    "    print(auth,\"OCCURENCE:\",counts[auth])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57f6c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train: (66,)\n",
      "Shape of Test: (17,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "\n",
    "print(\"Shape of Train:\",end=\" \")\n",
    "print(X_train.shape)\n",
    "print(\"Shape of Test:\",end=\" \")\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a87a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train: (66, 7876)\n",
      "Shape of Test: (17, 7876)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)  \n",
    "X_test = vectorizer.transform(X_test)    \n",
    "\n",
    "print(\"Shape of Train:\",end=\" \")\n",
    "print(X_train.shape)\n",
    "print(\"Shape of Test:\",end=\" \")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d795ff1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes\n",
      "accuracy score:  58.8235 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "pred = bnb.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)\n",
    "from sklearn.metrics import *\n",
    "print('Bernoulli Naive Bayes\\naccuracy score: ', round(100*accuracy_score(y_test, pred),4),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b6a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords,ngram_range=(1,2),max_features=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "X_train = vectorizer.fit_transform(X_train)  \n",
    "X_test = vectorizer.transform(X_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05831b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train: (66, 1000)\n",
      "Shape of Test: (17, 1000)\n",
      "Bernoulli Naive Bayes with MAX_FEATURES and NGRAM_RANGE\n",
      "accuracy score:  94.1176 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train:\",end=\" \")\n",
    "print(X_train.shape)\n",
    "print(\"Shape of Test:\",end=\" \")\n",
    "print(X_test.shape)\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "pred2 = bnb.predict(X_test)\n",
    "\n",
    "print('Bernoulli Naive Bayes with MAX_FEATURES and NGRAM_RANGE\\naccuracy score: ', round(100*accuracy_score(y_test, pred2),4),\"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb9aae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default logistic Regresssion\n",
      "accuracy score:  58.8235 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "regDefault = LogisticRegression()\n",
    " \n",
    "regDefault.fit(X_train, y_train)\n",
    "\n",
    "pred3 = regDefault.predict(X_test)\n",
    "confusion_matrix(y_test, pred)\n",
    "\n",
    "print('Default logistic Regresssion\\naccuracy score: ', round(100*accuracy_score(y_test, pred3),4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ad5afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced, Multinomial, LBFGS Logistic Regression\n",
      "accuracy score:  76.4706 %\n"
     ]
    }
   ],
   "source": [
    "regLoaded= LogisticRegression(multi_class='multinomial', solver='lbfgs',class_weight='balanced')\n",
    " \n",
    "regLoaded.fit(X_train, y_train)\n",
    "pred4 = regLoaded.predict(X_test)\n",
    "\n",
    "print('Balanced, Multinomial, LBFGS Logistic Regression\\naccuracy score: ', round(100*accuracy_score(y_test, pred4),4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecef5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 300 iterations Neural Network\n",
      "accuracy score:  76.4706 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier(max_iter=300)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "pred5 = nn.predict(X_test)\n",
    "print('max 300 iterations Neural Network\\naccuracy score: ', round(100*accuracy_score(y_test, pred5),4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d172e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 max iterations, Adam, adaptive LR, Neural Network\n",
      "accuracy score:  82.3529 %\n"
     ]
    }
   ],
   "source": [
    "nn2 = MLPClassifier(max_iter=2000,activation='relu',solver=\"adam\",learning_rate='adaptive')\n",
    "nn2.fit(X_train, y_train)\n",
    "\n",
    "pred6 = nn2.predict(X_test)\n",
    "print('2000 max iterations, Adam, adaptive LR, Neural Network\\naccuracy score: ', round(100*accuracy_score(y_test, pred6),4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6c7800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varied topology Neural Network\n",
      "accuracy score:  58.8235 %\n"
     ]
    }
   ],
   "source": [
    "nn3 = MLPClassifier(solver='adam', alpha=1e-5,activation='relu',learning_rate='adaptive',\n",
    "                   hidden_layer_sizes=(10,9,8,7,6,5,4,3,2,), random_state=1,max_iter=10000)\n",
    "nn3.fit(X_train, y_train)\n",
    "\n",
    "pred7 = nn3.predict(X_test)\n",
    "print('varied topology Neural Network\\naccuracy score: ', round(100*accuracy_score(y_test, pred7),4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac77c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varied topology Neural Network\n",
      "accuracy score:  76.4706 %\n"
     ]
    }
   ],
   "source": [
    "nn4 = MLPClassifier(solver='adam', alpha=1e-5,activation='relu',learning_rate='adaptive',\n",
    "                   hidden_layer_sizes=(66,132,264,132,66,), random_state=1,max_iter=10000)\n",
    "nn4.fit(X_train, y_train)\n",
    "\n",
    "pred8 = nn4.predict(X_test)\n",
    "print('varied topology Neural Network\\naccuracy score: ', round(100*accuracy_score(y_test, pred8),4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5536d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varied topology Neural Network\n",
      "accuracy score:  82.3529 %\n"
     ]
    }
   ],
   "source": [
    "nn5 = MLPClassifier(solver='adam', alpha=1e-5,activation='relu',learning_rate='adaptive',\n",
    "                   hidden_layer_sizes=(66,132,66,), random_state=1,max_iter=10000)\n",
    "nn5.fit(X_train, y_train)\n",
    "\n",
    "pred9 = nn5.predict(X_test)\n",
    "print('varied topology Neural Network\\naccuracy score: ', round(100*accuracy_score(y_test, pred9),4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49d6b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varied topology Neural Network\n",
      "accuracy score:  88.2353 %\n"
     ]
    }
   ],
   "source": [
    "nn6 = MLPClassifier(solver='adam',learning_rate='adaptive',\n",
    "                   hidden_layer_sizes=(33,66,33,), random_state=1,max_iter=10000)\n",
    "nn6.fit(X_train, y_train)\n",
    "\n",
    "pred10 = nn6.predict(X_test)\n",
    "print('varied topology Neural Network\\naccuracy score: ', round(100*accuracy_score(y_test, pred10),4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff480a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
