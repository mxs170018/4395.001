{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f481724",
   "metadata": {},
   "source": [
    "MXS170018, Portfolio Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0cc320c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "from nltk.book import *\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1abf47",
   "metadata": {},
   "source": [
    "## The text object is nothing more than strings wrapped together to enable peeking into texts. Here strings are considered tokens and they are used to perform basic analysis such as counting the tokens in the text, discovering certain tokens, and even a dispersion plot. This is interesting because Strings are immmutable in python, so this allows for more manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae5b507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar']\n"
     ]
    }
   ],
   "source": [
    "listA = text1.tokens[:20]\n",
    "print(listA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622382f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ConcordanceLine(left=['piercing', 'serpent', ',', 'even', 'Leviathan', 'that', 'crooked', 'serpent', ';', 'and', 'he', 'shall', 'slay', 'the', 'dragon', 'that', 'is', 'in', 'the'], query='sea', right=['.\"', '--', 'ISAIAH', '\"', 'And', 'what', 'thing', 'soever', 'besides', 'cometh', 'within', 'the', 'chaos', 'of', 'this', 'monster', \"'\", 's'], offset=759, left_print=' shall slay the dragon that is in the', right_print='.\" -- ISAIAH \" And what thing soever ', line=' shall slay the dragon that is in the sea .\" -- ISAIAH \" And what thing soever '), ConcordanceLine(left=['the', 'bottomless', 'gulf', 'of', 'his', 'paunch', '.\"', '--', 'HOLLAND', \"'\", 'S', 'PLUTARCH', \"'\", 'S', 'MORALS', '.', '\"', 'The', 'Indian'], query='Sea', right=['breedeth', 'the', 'most', 'and', 'the', 'biggest', 'fishes', 'that', 'are', ':', 'among', 'which', 'the', 'Whales', 'and', 'Whirlpooles', 'called', 'Balaene'], offset=823, left_print=' S PLUTARCH \\' S MORALS . \" The Indian', right_print='breedeth the most and the biggest fis', line=' S PLUTARCH \\' S MORALS . \" The Indian Sea breedeth the most and the biggest fis'), ConcordanceLine(left=['arpens', 'of', 'land', '.\"', '--', 'HOLLAND', \"'\", 'S', 'PLINY', '.', '\"', 'Scarcely', 'had', 'we', 'proceeded', 'two', 'days', 'on', 'the'], query='sea', right=[',', 'when', 'about', 'sunrise', 'a', 'great', 'many', 'Whales', 'and', 'other', 'monsters', 'of', 'the', 'sea', ',', 'appeared', '.', 'Among'], offset=872, left_print='cely had we proceeded two days on the', right_print=', when about sunrise a great many Wha', line='cely had we proceeded two days on the sea , when about sunrise a great many Wha'), ConcordanceLine(left=['proceeded', 'two', 'days', 'on', 'the', 'sea', ',', 'when', 'about', 'sunrise', 'a', 'great', 'many', 'Whales', 'and', 'other', 'monsters', 'of', 'the'], query='sea', right=[',', 'appeared', '.', 'Among', 'the', 'former', ',', 'one', 'was', 'of', 'a', 'most', 'monstrous', 'size', '.', '...', 'This', 'came'], offset=886, left_print='many Whales and other monsters of the', right_print=', appeared . Among the former , one w', line='many Whales and other monsters of the sea , appeared . Among the former , one w'), ConcordanceLine(left=['This', 'came', 'towards', 'us', ',', 'open', '-', 'mouthed', ',', 'raising', 'the', 'waves', 'on', 'all', 'sides', ',', 'and', 'beating', 'the'], query='sea', right=['before', 'him', 'into', 'a', 'foam', '.\"', '--', 'TOOKE', \"'\", 'S', 'LUCIAN', '.', '\"', 'THE', 'TRUE', 'HISTORY', '.\"', '\"'], offset=922, left_print=' waves on all sides , and beating the', right_print='before him into a foam .\" -- TOOKE \\' ', line=' waves on all sides , and beating the sea before him into a foam .\" -- TOOKE \\' ')]\n"
     ]
    }
   ],
   "source": [
    "listB = text1.concordance_list(\"sea\")[:5]\n",
    "print(listB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63425555",
   "metadata": {},
   "source": [
    "## It looks like it is the same as Python’s count method. They both count the number of times the given word appears in the text. The only difference is that the python count can also handle objects other than text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7c367b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(text1.count(\"sea\") ) # NLTK COUNT\n",
    "print(text1.count(9)) #Python count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200902b5",
   "metadata": {},
   "source": [
    "# Excerpt from Big Little Lies by Liane Moriarty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd0ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['While', 'Chloe', 'was', 'busy', 'bossing', 'the', 'other', 'children', 'around', 'at']\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"While Chloe was busy bossing the other children around at orientation (her gift was bossiness, she was going to run a corporation one day), Madeline was going to have coffee and cake with her friend Celeste. Celeste’s twin boys were starting school next year too, so they’d be running amuck at orientation. (Their gift was shouting. Madeline had a headache after five minutes in their company.) Celeste always bought exquisite and very expensive birthday presents, so that would be nice. After that, Madeline was going to drop Chloe off with her mother-in-law, and then have lunch with some friends before they all rushed off for school pickup. The sun was shining.\" \n",
    "tokens = word_tokenize(raw_text)\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef524af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['While Chloe was busy bossing the other children around at orientation (her gift was bossiness, she was going to run a corporation one day), Madeline was going to have coffee and cake with her friend Celeste.', 'Celeste’s twin boys were starting school next year too, so they’d be running amuck at orientation.', '(Their gift was shouting.', 'Madeline had a headache after five minutes in their company.)', 'Celeste always bought exquisite and very expensive birthday presents, so that would be nice.', 'After that, Madeline was going to drop Chloe off with her mother-in-law, and then have lunch with some friends before they all rushed off for school pickup.', 'The sun was shining.']\n"
     ]
    }
   ],
   "source": [
    "sents = sent_tokenize(raw_text)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb03bee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['while', 'chloe', 'wa', 'busi', 'boss', 'the', 'other', 'children', 'around', 'at', 'orient', '(', 'her', 'gift', 'wa', 'bossi', ',', 'she', 'wa', 'go', 'to', 'run', 'a', 'corpor', 'one', 'day', ')', ',', 'madelin', 'wa', 'go', 'to', 'have', 'coffe', 'and', 'cake', 'with', 'her', 'friend', 'celest', '.', 'celest', '’', 's', 'twin', 'boy', 'were', 'start', 'school', 'next', 'year', 'too', ',', 'so', 'they', '’', 'd', 'be', 'run', 'amuck', 'at', 'orient', '.', '(', 'their', 'gift', 'wa', 'shout', '.', 'madelin', 'had', 'a', 'headach', 'after', 'five', 'minut', 'in', 'their', 'compani', '.', ')', 'celest', 'alway', 'bought', 'exquisit', 'and', 'veri', 'expens', 'birthday', 'present', ',', 'so', 'that', 'would', 'be', 'nice', '.', 'after', 'that', ',', 'madelin', 'wa', 'go', 'to', 'drop', 'chloe', 'off', 'with', 'her', 'mother-in-law', ',', 'and', 'then', 'have', 'lunch', 'with', 'some', 'friend', 'befor', 'they', 'all', 'rush', 'off', 'for', 'school', 'pickup', '.', 'the', 'sun', 'wa', 'shine', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmed = [PorterStemmer().stem(t) for t in tokens]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee90d4f",
   "metadata": {},
   "source": [
    "# Stem-Lemma\n",
    "boss-bossing\n",
    "\n",
    "children-child\n",
    "\n",
    "orient-orientation\n",
    "\n",
    "bossi-bossiness\n",
    "\n",
    "expense-expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08109c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['While', 'Chloe', 'wa', 'busy', 'bossing', 'the', 'other', 'child', 'around', 'at', 'orientation', '(', 'her', 'gift', 'wa', 'bossiness', ',', 'she', 'wa', 'going', 'to', 'run', 'a', 'corporation', 'one', 'day', ')', ',', 'Madeline', 'wa', 'going', 'to', 'have', 'coffee', 'and', 'cake', 'with', 'her', 'friend', 'Celeste', '.', 'Celeste', '’', 's', 'twin', 'boy', 'were', 'starting', 'school', 'next', 'year', 'too', ',', 'so', 'they', '’', 'd', 'be', 'running', 'amuck', 'at', 'orientation', '.', '(', 'Their', 'gift', 'wa', 'shouting', '.', 'Madeline', 'had', 'a', 'headache', 'after', 'five', 'minute', 'in', 'their', 'company', '.', ')', 'Celeste', 'always', 'bought', 'exquisite', 'and', 'very', 'expensive', 'birthday', 'present', ',', 'so', 'that', 'would', 'be', 'nice', '.', 'After', 'that', ',', 'Madeline', 'wa', 'going', 'to', 'drop', 'Chloe', 'off', 'with', 'her', 'mother-in-law', ',', 'and', 'then', 'have', 'lunch', 'with', 'some', 'friend', 'before', 'they', 'all', 'rushed', 'off', 'for', 'school', 'pickup', '.', 'The', 'sun', 'wa', 'shining', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatize = [WordNetLemmatizer().lemmatize(t) for t in tokens]\n",
    "print(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90953e20",
   "metadata": {},
   "source": [
    "The functionality of the NLTK library is great for these small texts but I wonder how it would fare with larger bodies of text. How much space does a token take compared to a string? It seems that the NLTK functionality is better at getting info on the text than actually modifying it. That is what I gathered from this assignment. The code seems to be heavliy Object-Oriented in that it inherits some of the functions, such as the count() function from a superclass such as the token class. This adds to the maintainability of the tool kit. It seems the code is simple, and in the python style. I think I will use NLTK to analyze bodies of text in order to look for certain patterns. I believe this could be invaluable for parsing JSON input data, or for exracting variables for analysis from peculiar text-based data. I think i can also use it to help my sister because she is getting a degree in library science, so she will probably end up using it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
